---
title: "q3"
output: html_document
bibliography: bibliography.ris
---


```{r setup-t3, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
set.seed(4321)
```


```{r deps-t3, echo=FALSE, include=FALSE, message=FALSE}
if(!require(rJava)) install.packages('rJava')
if(!require(caret)) install.packages("caret", repos = mirrorUrl)
if(!require(RWeka)) install.packages("RWeka", repos = mirrorUrl)
#e1071
if(!require(e1071)) install.packages("e1071", repos = mirrorUrl)
#libcoin
if(!require(coin)) install.packages("coin", repos = mirrorUrl)
#partykit
if(!require(partykit)) install.packages("partykit", repos = mirrorUrl)
#rpart
if(!require(rpart.plot)) install.packages("rpart.plot", repos = mirrorUrl)
#
library("e1071")
library("caret")
library("RWeka")
library("rpart.plot")
library("libcoin")
library("partykit")
```

<section>

#Task 3: Build Train and Test a Decision Tree type Classifier

##Premise

>You need to construct, train and test Decision Tree type classifier (C4.5, Random Forest) in R. Train and test your decision tree classifier using the training and test sets generated based on the methods tried as part of the 2nd Task.

<!--
• Building of Decision Tree type classifier (C4.5, Random Forest) in R 8
• Training of Decision Tree type classifier (C4.5, Random Forest) in R 8
• Testing of Decision Tree type classifier (C4.5, Random Forest) 9
-->

##C4.5 Decision Tree

Finding the C4.5 method as an existing library within R, brought up more than one option, both appear to use a an open-source equivalent of C4.5 rather than an official C4.5 implementation; other options we to use C5.0 which apparently supercedes C4.5; seeing as the task was to investigate C4.5, J48 has been chosen as a more faithful example of the algorithm.

Below is not only an investigation into C4.5 but also, a comparison of two variations.

###The J48 method

```{r dt-c4_5_j48-h}
#method = 'J48'
#as.factor(
#dt.c4_5_h <- J48(rings~., holdout.training) 
dt.c4_5_j48_h <- J48(as.factor(rings)~., holdout.training) 
```

The J48 function is extremely quick with the dataset, trainig takes less than a second, which on it's on is not necessarily worthy of note but certainly more interesting when compared to the speed of using the caret train method with a "J48" method arguemtn value.


###The caret train J48 argument

```{r dt-c4_5_train-h}
dt.c4_5_h2 <- train(as.factor(rings) ~., method="J48", holdout.training, tuneLength = 8)
#dt.c4_5_h <- train(rings ~., method="J48", data=holdout.training, tuneLength = 8)

#dt.c4_5_h
#dt.c4_5_h2$finalModel
```

Whilst in comparisons to other forms of training and data-mining algorithms, under 5 minutes for a 4,000 by 9 dataset might seem okay, in comparison to the J48 function, there seems to be something at odds. The proof will be in the comparison of the two models with regard to accuracy on the test datset.

###Comparing the two C4.5/J48 methods


```{r dt-c4_5h_test}
#plot(dt.c4_5_h$finalModel, box.palette = "Reds", tweak = 1.2)
holdout.test_rings <- holdout.testing$rings
dt.c4_5_h_test <- predict(dt.c4_5_h, newdata = holdout.testing)
table(dt.c4_5_h_test, holdout.test_rings)
#confusionMatrix(dt.c4_5_h_test, holdout.testing$rings)
#table(factor(dt.c4_5_h_test, levels=min(holdout.test_rings):max(holdout.test_rings)), factor(holdout.test_rings, levels=min(holdout.test_rings):max(holdout.test_rings)))
holdout.test_levels <- min(holdout.test_rings):max(holdout.test_rings)
confusionMatrix(factor(dt.c4_5_h_test, levels=holdout.test_levels), factor(holdout.test_rings, levels = holdout.test_levels))
```

```{r dt-c4_5h2_test}
#plot(dt.c4_5_h$finalModel, box.palette = "Reds", tweak = 1.2)
#holdout.test_rings <- holdout.testing$rings
dt.c4_5_h2_test <- predict(dt.c4_5_h2, newdata = holdout.testing)
table(dt.c4_5_h2_test, holdout.test_rings)
#confusionMatrix(dt.c4_5_h_test, holdout.testing$rings)
#table(factor(dt.c4_5_h_test, levels=min(holdout.test_rings):max(holdout.test_rings)), factor(holdout.test_rings, levels=min(holdout.test_rings):max(holdout.test_rings)))
#holdout.test_levels <- min(holdout.test_rings):max(holdout.test_rings)
confusionMatrix(factor(dt.c4_5_h2_test, levels=holdout.test_levels), factor(holdout.test_rings, levels = holdout.test_levels))
```

```{r dt-c4_5h2_fm_test}
dt.c4_5_h2_fm <- dt.c4_5_h2$finalModel
dt.c4_5_h2_fm_test <- predict(dt.c4_5_h2_fm, newdata = holdout.testing)
table(dt.c4_5_h2_fm_test, holdout.test_rings)
#confusionMatrix(dt.c4_5_h_test, holdout.testing$rings)
#table(factor(dt.c4_5_h_test, levels=min(holdout.test_rings):max(holdout.test_rings)), factor(holdout.test_rings, levels=min(holdout.test_rings):max(holdout.test_rings)))
#holdout.test_levels <- min(holdout.test_rings):max(holdout.test_rings)
confusionMatrix(factor(dt.c4_5_h2_fm_test, levels=holdout.test_levels), factor(holdout.test_rings, levels = holdout.test_levels))
```

```{r dt-test}
#set.seed(1958)  # set a seed to get replicable results
#train <- createFolds(iris$Species, k=10)
#C45Fit <- train(Species ~., method="J48", data=iris,
#                tuneLength = 5,
#                trControl = trainControl(
#                  method="cv", indexOut=train))
```

</section>
