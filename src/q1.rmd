---
title: "q1"
output: html_document
bibliography: bibliography.ris
---


```{r setup-t1, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(4321)
```


```{r deps-t1, echo=FALSE, include=FALSE, message=FALSE}
mirrorUrl = "http://cran.ma.imperial.ac.uk"

# Install and load all packages up-front!
if(!require(readxl)) install.packages("readxl", repos = mirrorUrl)
if(!require(Metrics)) install.packages("Metrics", repos = mirrorUrl)
if(!require(gridExtra)) install.packages("gridExtra", repos = mirrorUrl)
if(!require(scales)) install.packages("scales", repos = mirrorUrl)
if(!require(data.table)) install.packages("data.table", repos = mirrorUrl)
if(!require(ggplot2)) install.packages("ggplot2", repos = mirrorUrl)
if(!require(caret)) install.packages("caret", repos = mirrorUrl)
#
library("readxl")
library("Metrics")
library("scales")
library("data.table")
library(ggplot2)
library(grid)
library(gridExtra)
library(knitr)
library(caret)
```

<section>

#Task 1: Data Set Selection and Visualisation

##Premise

>You need to select a data set of your own choice (i.e. you may use a dataset already used before in the lab, or from the literature review) for the purposes of building training and validating the above type of classifiers 1-3. With the aid of R package visualise and justify the properties of the selected data set.

<!--
• Data Set summary of main properties 5
• Visualisation in R of main data set properties 5
-->

##Picking the data set

The first task was to find out where to look for datasets, most sources of advice referred to the UCI repository, other sources often reused this data and hosted it in a new format, like Kaggle. After looking online for suitable datasets, specifically for the problem of classification, 2 datasets were possible candidates for study; between the Taiwanese Credit Card dataset and the Abalone shellfish dataset, I opted for the Abalone dataset on the basis that if has fewer variables and fewer instances, so it should be easier to work with without so much preparation; the credit card data would require more considered cleansing of outliers and potentially pruning of variables considered as well as PCA for dimensionality reduction.

The Abalone dataset has a little over 4,000 instances compared to 30,000 for the Credit Card dataset, 8 attributes for Abalone compared to 24 for the Credit Card data. Hopefully the dimensionality of the Abalone dataset should lend itself to less data cleansing because the variables are concrete characteristics of the animals:

 - Sex
 - Length
 - Diameter
 - Height
 - Whole weight
 - Shucked weight
 - Viscera weight
 - Shell weight
 - Rings 

###How to classify this data

The typical way to classify this data, is to determine approximate age based on the ring value, according to the UCI page for this dataset, the rings roughly suggest age such that \(y = r + 2.5\), where _y_ is number of years and _r_ is number of rings. The simplest approach is to attempt to guess the correct number of rings for a test instance based on other attributes.

###Getting the data

Having downloaded the data from the UCI repository we need convert the data into a table and check it's usable.

```{r read-abalone-1}
abalone_data = data.frame(read.table("../assets/data/abalone.data", sep = ","))
abalone_attr_names = c("sex", "length", "diameter", "height", "weight.whole", "weight.shucked", "weight.viscera", "weight.shell", "rings")
colnames(abalone_data) = abalone_attr_names

#We need to check there are no missing values, as if any instances are incomlete we will need to remove
missing_vals = sum(is.na(abalone_data))
print(c("Number of missing values:", missing_vals), quote = FALSE)
```

Here's a glance at the dataset.

```{r show-abalone-1}
head(abalone_data)
abalone_summary = summary(abalone_data)

grid.table(abalone_summary)
kable(abalone_summary)

```

### The attributes explained

The Abalone is a type of shellfish and each attribute describes a characteristic of the animal. Not being an expert on this animal, I've had to research a little bit about the Abalone in order to get an idea of what these traits are. Knowing a bit more about these properties, should hopefully lead to a better understanding of the data. What follows is a list of definitions for each column.

<dl>
  <dt>sex</dt>
  <dd>M (male), F (female), or I (infant). Presumably, an infant Abalone lacks a sex or it's too hard to identify</dd>
  <dt>length</dt>
  <dd>Longest shell measurement, in millimetres</dd>
  <dt>diameter</dt>
  <dd>Perpendicular measurement to measured length, in millimetres</dd>
  <dt>height</dt>
  <dd>Height of abalone, including body, in millimetres</dd>
  <dt>weight.whole</dt>
  <dd>Weight of whole abalone, in grams</dd>
  <dt>weight.shucked</dt>
  <dd>Weight of meat alone, in grams</dd>
  <dt>weight.viscera</dt>
  <dd>Weight of guts and other non meat alone, in grams</dd>
  <dt>weight.shell</dt>
  <dd>weight of shell alone, after drying, in grams</dd>
  <dt>rings</dt>
  <dd>Number of rings in the shell, strongly correlated to age but with a delta</dd>
</dl>

### A little bit of basic data cleansing

The data was checked to see if there were any missing values but it's also worth checking of some values are technically impossible and therefore belonging to incorrect entries that need to be removed; to do this, all values are iterated over to check for assignments of 0, indicating bad data.

```{r basic-data-sanity}
abalone_numeric_attr <- abalone_attr_names[which(abalone_attr_names!="sex")] 

for (abalone_attr in abalone_numeric_attr)
{
  bad_vals = abalone_data[abalone_data[abalone_attr] == 0, ]
  #col_data = unlist(abalone_data[abalone_attr])
  if (nrow(bad_vals) > 0)
  {
    print(abalone_attr)
    print(abalone_data[abalone_data[abalone_attr] == 0, ])
  }

}

rm(bad_vals)
```

It appears that there are two height values that are incorrect, so we should remove these instances from our dataset.

```{r basic-data-sanity-2}
abalone_data$height[abalone_data$height==0] = NA
abalone_data = na.omit(abalone_data)
```

It's also worth examining the weight data, to ensure that the total data is not less than the combined values to the other weight values.

```{r crazy-weight}
abalone_data_bad_weight = abalone_data[(abalone_data$weight.whole - (abalone_data$weight.shucked + abalone_data$weight.viscera + abalone_data$weight.shell)) < 0,]

head(abalone_data_bad_weight)
print(paste(c("Number of instances where total weight is less than constiuent weights:", nrow(abalone_data_bad_weight)), sep = ""), quote = FALSE)
```

It would appear that the data isn't completely sanitized, with this sort of erroneous data entry needing to be handled as well. The simplest option is to rule out these instances as well.
<!--Given that the mean value for the whole weight is 0.8287g, -->
```{r cleanse-crazy-weight}
abalone_data <- abalone_data[!(abalone_data$weight.whole - (abalone_data$weight.shucked + abalone_data$weight.viscera + abalone_data$weight.shell)) < 0,]
```

### A graphical look at the attributes 

Below is an examination of each attribute to see if there are any obvious outliers that might need to be removed

```{r attribute-graphs}
#boxplot(scale(abalone_data), main="Looking at the data graphically", xlab="Abalone Attributes", ylab="Values") 

plot(abalone_data$sex)

for (abalone_attr in abalone_numeric_attr)
{
  #print(abalone_attr)
  col_data = unlist(abalone_data[abalone_attr])
  #print(col_data)
  plot(density(col_data), xlab=abalone_attr, main=paste(c("Density of ", abalone_attr), collapse = ''))
}

rm(abalone_attr)
rm(col_data)

```


In order to work out which attributes should be considered to have valid outliers, I've gone with a heuristic approach, choosing to look at the distance between the uppermost outliers for each attribute and it's nearest neighbour.

```{r find-sparse-tails-abalone}
#Create a list to populate with our tail neighbour distances
tail_deltas <- c()

abalone_data_no_sex = abalone_data[, -1]

for (attrib in abalone_data_no_sex) {
 #get the last two values
 data_tails <- tail(sort(attrib),2)
 #push the delta on to our list 
 tail_deltas <- c(tail_deltas, diff(data_tails))
}

#grab out attribute keys to include in our new table/frame
attributes <- names(abalone_data_no_sex)

#make a new dataframe from 
dataframe <- data.frame(attributes = attributes, tail_neighbour_d=tail_deltas)

#get the order for the nearest neighbour starting with the greatest distance and descending
neighbour_order <- order(dataframe$tail_neighbour_d, decreasing=TRUE)

#now apply the order to the frame
sorted_attributes_by_neighbour_d <- dataframe[ neighbour_order, ]
sorted_attributes_by_neighbour_d
```

While rings is at the top of the leader-board regarding the delta, it's important to take into account that this data isn't scaled; it's very likely that this outlier is the results of a particularly lucky Abalone that managed to live longer than the rest of the long tail through some luck. Given that the other values are meant to be in grams and millimetres, it's reasonable to compare values like for like in this instance. As such the weight deltas as comparable and can be excluded from outlier cleansing, with the same applying to diameter and length; height seems to be anomalous though and will need further attention.


It's easier to see on a box-plot that one value is way out far from any neighbours, with its nearest neighbour also having no nearby neighbour; we could probably benefit just from removing the two farthest outliers.

```{r}
boxplot(abalone_data$height)
```
```{r}
abalone_data_cleansed <- abalone_data[ abalone_data$height < .5, ]
boxplot(abalone_data_cleansed$height)
```

#### Correlation between the 'rings' attribute and attributes pertaining to length or mass.

Seeing as the intent is to see if classification can be used to determine approximate age from physical attributes (aside from rings), it's worth looking for existing correlations between the attributes and the number of rings. 

```{r}
  qplot(x = length, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = diameter, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = height, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = weight.whole, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = weight.shucked, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = weight.viscera, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
  qplot(x = weight.shell, 
      y = rings, 
      data = abalone_data_cleansed,
      alpha = I(0.2), # alpha to help convery density
      geom = "jitter") + # jitter so points don't stack so much
  geom_smooth(method = lm)
```

###Picking data attributes to select

With our cleansed data we can see that there is an evident correlation  between all of these attributes and the number of rings but in particular those relating to physical size show the strongest relationship as the points best match the line of best fit; the weight values are distributed in such a way that there's a little curve away from the line as you reach 0 on both axes and they also seem to diverge more from the line as the dimension values increase. Should any attributes be selected as ones to work with, discarding the others, it would be:

 - length
 - diameter
 - height
 - weight.whole

Given that the all attributes appear to display a fairly linear relationship to the ring count we can use r-squared, otherwise known as the Coefficient of Determination to verify how well the data matches the line of best fit

```{r}
abalone.lm_length <- lm(data = abalone_data_cleansed, formula = rings ~ length)
abalone.lm_diameter <- lm(data = abalone_data_cleansed, formula = rings ~ diameter)
abalone.lm_height <- lm(data = abalone_data_cleansed, formula = rings ~ height)
abalone.lm_weight.whole <- lm(data = abalone_data_cleansed, formula = rings ~ weight.whole)
abalone.lm_weight.shucked <- lm(data = abalone_data_cleansed, formula = rings ~ weight.shucked)
abalone.lm_weight.viscera <- lm(data = abalone_data_cleansed, formula = rings ~ weight.viscera)
abalone.lm_weight.shell <- lm(data = abalone_data_cleansed, formula = rings ~ weight.shell)

abalone.r_squareds <- c(
  summary(abalone.lm_length)$adj.r.squared,
summary(abalone.lm_diameter)$adj.r.squared,
summary(abalone.lm_height)$adj.r.squared,
summary(abalone.lm_weight.whole)$adj.r.squared,
summary(abalone.lm_weight.shucked)$adj.r.squared,
summary(abalone.lm_weight.viscera)$adj.r.squared,
summary(abalone.lm_weight.shell)$adj.r.squared
)

abalone_numeric_attr_no_rings <- abalone_numeric_attr[which(abalone_numeric_attr!="rings")] 

#make a new dataframe from 
dataframe.rsquareds <- data.frame(attributes = abalone_numeric_attr_no_rings, r_squared=abalone.r_squareds)

#get the order for the nearest neighbour starting with the greatest distance and descending
rsquareds_order <- order(dataframe.rsquareds$r_squared, decreasing=TRUE)

#now apply the order to the frame
sorted_attributes_by_r_squared <- dataframe.rsquareds[ rsquareds_order, ]
sorted_attributes_by_r_squared

#abalone.lm_length
```

After looking at these results it may be wiser to consider using the shell weight alone if necessary; the r-squared value isn't a perfect predictor of the fitness but perhaps in this case, it could make more sense to use a weight value that could fluctuate less in nature. Selection of the attributes relating to size appear to be validated.

####Substantiating the selection 

With the use of a correlation matrix, it's possible to further validate which attributes could be worth focusing on:

```{r abalone-feature-correlation}
# calculate correlation matrix
correlationMatrix <- cor(abalone_data_cleansed[,2:9])
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally &gt;0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)

abalone.correlation <- data.frame(correlation=correlationMatrix[,8])
#get rid of rings, that's obviously going to be max correlation to itself!
abalone.correlation <- data.frame(attributes=rownames(abalone.correlation)[1:7], 'correlation to rings'=abalone.correlation[1:7, 0:1])

#get the order for correlations
correlation_order <- order(abalone.correlation$correlation, decreasing=TRUE)

#now apply the order to the frame
sorted_correlation_order <- abalone.correlation[ correlation_order, 1:2]
print(sorted_correlation_order)

```

The correlation between ring values and the other attributes, when ordered, actually matches the order of the r-squared values; so much so, that weight.shell should be considered the primary correlate of them all, followed by height. 

##Creating a simpler classifaction value

Given that the number of rings is actually a range of integers from 1 to 29, to use each individual possible integer presents a problem; firstly as the ring value cannot be considered continuous it's not really sensible to treat it as such, thus converting to a a numeric floating range is not appropriate; in addition to this, the dataset might not have instances that cover every single possible ring value between 1 and 29, which will cause inaccuracy in some of the models.

An alternative dataset can be created that mitigates this issue by creating an approximate age factor; classification of the Abalone can be more loosely done against age ranges, like _young, middle, old_ with the test instances still being compared by other attributes and mapped to one of these age group factor values. The split will be determined by the ring/age spread of the sampled population of Abalones, such that about a 1/3 of the sample size is in each age_group. This is because the number of Abalones with rings above 12 starts to drop off quite acutely and as a percentage those above 15 even are a small minority, despite the highest values nearing 30 rings.

```{r abalone-age-granges}
summary(abalone_data_cleansed$rings)
quantile(abalone_data_cleansed$rings, c(1/3, 2/3)) 
abalone_age_groups <- cut(abalone_data_cleansed$rings, breaks=c(-Inf, 9, 12, Inf), labels=c("young","middle","old"))

summary(abalone_age_groups)

abalone_data_cleansed_age_groups <- subset(abalone_data_cleansed, select=-rings)
abalone_data_cleansed_age_groups$age_group <- abalone_age_groups
rm(abalone_age_groups)
```

</section>
