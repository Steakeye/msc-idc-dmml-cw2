---
title: "q1"
output: html_document
bibliography: bibliography.ris
---


```{r setup-t1, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r deps-t1, echo=FALSE, include=FALSE, message=FALSE}
mirrorUrl = "http://cran.ma.imperial.ac.uk"

# Install and load all packages up-front!
if(!require(readxl)) install.packages("readxl", repos = mirrorUrl)
if(!require(Metrics)) install.packages("Metrics", repos = mirrorUrl)
if(!require(scales)) install.packages("scales", repos = mirrorUrl)
if(!require(data.table)) install.packages("data.table", repos = mirrorUrl)
if(!require(ggplot2)) install.packages("ggplot2", repos = mirrorUrl)
#
library("readxl")
library("Metrics")
library("scales")
library("data.table")
library(ggplot2)
library(grid)
library(gridExtra)
library(knitr)
```

<section>

#Task 1: Data Set Selection and Visualisation

##Premise

>You need to select a data set of your own choice (i.e. you may use a dataset already used before in the lab, or from the literature review) for the purposes of building training and validating the above type of classifiers 1-3. With the aid of R package visualise and justify the properties of the selected data set.

<!--
• Data Set summary of main properties 5
• Visualisation in R of main data set properties 5
-->

##Picking the data set

The first task was to find out where to look for datasets, most sources of advice referred to the UCI repository, other sources often reused this data and hosted it in a new format, like Kaggle. After looking online for suitable datasets, specifically for the problem of classification, 2 datasets were possible candidates for study; between the Taiwanese Credit Card dataset and the Abalone shellfish dataset, I opted for the Abalone dataset on the basis that if has fewer variables and fewer intances, so it should be easier to work with without so much preparation; the credit card dats would require more considerated cleansing of outliers and potentially pruning of variables considered as well as PCA for dimensionality reduction.

The Abalone dataset has a litle over 4,000 instances complared to 30,000 for the Credit Card dataset, 8 attrbitues for Abelone compared to 24 for the Credit Card data. Hopefully the dimensionality of the Abalone datset should lend itself to less data cleansing because the variables are concrete characteristics of the animals:

 - Sex
 - Length
 - Diameter
 - Height
 - Whole weight
 - Shucked weight
 - Viscera weight
 - Shell weight
 - Rings 

###How to classify this data

The typical way to classify this data, is to determine approximate age based on the ring value, according to the UCI page for this datset, the rings roughtly suggest age such that \(y = r + 2.5\), where y is number of years and r is number of rings. Classification of the Abalone suggests that they are grouped by age converted to a factor, like _young, middle, old_; then and test instance can be compared by other attrbibutes and mapped to one of these age group factor values.

###Getting the data

Having downloaded the data from the UCI repo we need convert the data into a table and check it's usable.

```{r read-abalone-1}
abalone_data = data.frame(read.table("../assets/data/abalone.data", sep = ","))
abalone_attr_names = c("sex", "length", "diameter", "height", "weight.whole", "weight.shucked", "weight.viscera", "weight.shell", "rings")
colnames(abalone_data) = abalone_attr_names

#We need to check there are no missing values, as if any instances are incomlete we will need to remove
missing_vals = sum(is.na(abalone_data))
print(c("Number of missing values:", missing_vals), quote = FALSE)
```

Here's a glance at the dataset.

```{r show-abalone-1}
head(abalone_data)
abalone_summary = summary(abalone_data)

grid.table(abalone_summary)
kable(abalone_summary)

```
### The attributes explained

The Abalone ius a type of shellfish and each attribute describes a characteristic of the animal. Not being an expert on this animal, I've had to research a little bit about the Abalone in order to get an idea of what these traits are. Knowing a bit more about these properites, should hopefully lead to a better understanding of the data. What follwois is a list of definitions for each column.

<dl>
  <dt>sex</dt>
  <dd>M (male), F (female), or I (infant). Presumably, an infant Abalone lacks a sex or it's too hard to identify</dd>
  <dt>length</dt>
  <dd>Longest shell measurement, in millimetres</dd>
  <dt>diameter</dt>
  <dd>Perpendicular measurement to measured length, in millimetres</dd>
  <dt>height</dt>
  <dd>Height of abalone, including body, in millimetres</dd>
  <dt>weight.whole</dt>
  <dd>Weight of whole abalone, in grams</dd>
  <dt>weight.shucked</dt>
  <dd>Weight of meat alone, in grams</dd>
  <dt>weight.viscera</dt>
  <dd>Weight of guts and other non meat alone, in grams</dd>
  <dt>weight.shell</dt>
  <dd>weight of shell alone, after drying, in grams</dd>
  <dt>rings</dt>
  <dd>Number of rings in the shell, strongly correlated to age but with a delta</dd>
</dl>

### A little bit of basic data cleansing

The data was checked to see if there were any missing values but it's also worth checking of some values are technically impossible and therefore belonging to incorrect entires that need to be removed; to do this, all values are iterated over to check for assignments of 0, indicating bad data.

```{r basic-data-sanity}

for (abalone_attr in abalone_numeric_attr)
{
  bad_vals = abalone_data[abalone_data[abalone_attr] == 0, ]
  #col_data = unlist(abalone_data[abalone_attr])
  if (nrow(bad_vals) > 0)
  {
    print(abalone_attr)
    print(abalone_data[abalone_data[abalone_attr] == 0, ])
  }

}

rm(bad_vals)
```

It appears that there are two height values that are incorrect, so we should remove these instances from our dataset.

```{r basic-data-sanity}
abalone_data$height[abalone_data$height==0] = NA
abalone_data = na.omit(abalone_data)
```

It's also worth examining the weight data, to ensure that the total data is not less than the combined values to the other weight values.

```{r crazy-weight}
abalone_data_bad_weight = abalone_data[(abalone_data$weight.whole - (abalone_data$weight.shucked + abalone_data$weight.viscera + abalone_data$weight.shell)) < 0,]

head(abalone_data_bad_weight)
print(paste(c("Number of instances where total weight is less than constiuent weights:", nrow(abalone_data_bad_weight)), sep = ""), quote = FALSE)
```

It would appear that the data isn't completely sanitized, with this sort of erroneous data entry needing to be handled as well. The simplest option is to rule out these instances as well.
<!--Given that the mean value for the whole weight is 0.8287g, -->
```{r cleanse-crazy-weight}
abalone_data <- abalone_data[!(abalone_data$weight.whole - (abalone_data$weight.shucked + abalone_data$weight.viscera + abalone_data$weight.shell)) < 0,]
```

### A graphical look at the attributes 

Below is an examination of each attribute to see if there are any obvious outliers that might need to be removed

```{r attribute-graphs}
#boxplot(scale(abalone_data), main="Looking at the data graphically", xlab="Abalone Attributes", ylab="Values") 

plot(abalone_data$sex)

abalone_numeric_attr <- abalone_attr_names[which(abalone_attr_names!="sex")] 

for (abalone_attr in abalone_numeric_attr)
{
  #print(abalone_attr)
  col_data = unlist(abalone_data[abalone_attr])
  #print(col_data)
  plot(density(col_data), xlab=abalone_attr, main=paste(c("Density of ", abalone_attr), collapse = ''))
}

rm(col_data)

```

```

</section>
